{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. 必要なモジュールのインポートと初期設定\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from retry import retry\n",
    "import time\n",
    "import logging\n",
    "import sqlite3\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# ロギング設定\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='scraping.log'\n",
    ")\n",
    "\n",
    "# ヘッダー設定\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# SUUMOの東京23区の物件検索URL\n",
    "url = 'https://suumo.jp/jj/chintai/ichiran/FR301FC001/?ar=030&bs=040&ta=13&sc=13101&sc=13102&sc=13103&sc=13104&sc=13105&sc=13113&sc=13106&sc=13107&sc=13108&sc=13118&sc=13121&sc=13122&sc=13123&sc=13109&sc=13110&sc=13111&sc=13112&sc=13114&sc=13115&sc=13120&sc=13116&sc=13117&sc=13119&cb=0.0&ct=9999999&mb=0&mt=9999999&et=9999999&cn=9999999&shkr1=03&shkr2=03&shkr3=03&shkr4=03&sngz=&po1=25&pc=50&page={}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. データベースの初期化と管理\n",
    "def init_database():\n",
    "    \"\"\"データベースの初期化\"\"\"\n",
    "    conn = sqlite3.connect('suumo_properties_focused.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS properties (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        scrape_date TEXT,\n",
    "        nearest_station1 TEXT,\n",
    "        nearest_station2 TEXT\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    conn.commit()\n",
    "    return conn, cursor\n",
    "\n",
    "def insert_to_database(conn, cursor, data_samples):\n",
    "    \"\"\"データベースへの挿入\"\"\"\n",
    "    scrape_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    insert_query = '''\n",
    "    INSERT INTO properties (\n",
    "        scrape_date, nearest_station1, nearest_station2\n",
    "    ) VALUES (?, ?, ?)\n",
    "    '''\n",
    "    \n",
    "    insert_data = [\n",
    "        (\n",
    "            scrape_date,\n",
    "            sample['station1'],\n",
    "            sample['station2']\n",
    "        )\n",
    "        for sample in data_samples\n",
    "    ]\n",
    "    \n",
    "    cursor.executemany(insert_query, insert_data)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3. CSV保存関数\n",
    "def save_to_csv(data_samples):\n",
    "    \"\"\"CSVファイルに保存\"\"\"\n",
    "    keys = ['scrape_date', 'station1', 'station2']\n",
    "    with open('suumo_properties.csv', 'a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "        if file.tell() == 0:  # ファイルが空の場合、ヘッダーを書き込む\n",
    "            writer.writeheader()\n",
    "        writer.writerows(data_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### 4. スクレイピング関連の関数\n",
    "@retry(tries=3, delay=10, backoff=2)\n",
    "def load_page(url):\n",
    "    \"\"\"ページの読み込み\"\"\"\n",
    "    try:\n",
    "        html = requests.get(url, headers=headers, timeout=20)  # タイムアウトを20秒に設定\n",
    "        html.raise_for_status()\n",
    "        return BeautifulSoup(html.content, 'html.parser')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"ページ読み込みエラー: {e}\")\n",
    "        raise\n",
    "\n",
    "def get_total_pages(soup):\n",
    "    \"\"\"総ページ数の取得\"\"\"\n",
    "    try:\n",
    "        page_links = soup.find('div', class_='pagination-parts').find_all('a')\n",
    "        return int(page_links[-2].text)\n",
    "    except:\n",
    "        return 100  # デフォルト値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5. データ抽出ロジック\n",
    "def extract_property_data(property_item):\n",
    "    \"\"\"物件データの抽出\"\"\"\n",
    "    property_data = []\n",
    "    \n",
    "    try:\n",
    "        # 最寄り駅情報\n",
    "        station_info = property_item.find(class_='cassetteitem_detail-col2')\n",
    "        stations = station_info.find_all(class_='cassetteitem_detail-text')\n",
    "        station1 = stations[0].text if stations else '不明'\n",
    "        station2 = stations[1].text if len(stations) > 1 else '不明'\n",
    "        \n",
    "        # 部屋情報の取得\n",
    "        rooms = property_item.find(class_='cassetteitem_other')\n",
    "        for room in rooms.find_all(class_='js-cassette_link'):\n",
    "            room_data = {\n",
    "                'station1': station1,\n",
    "                'station2': station2\n",
    "            }\n",
    "            \n",
    "            property_data.append(room_data)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"物件データ抽出エラー: {e}\")\n",
    "    \n",
    "    return property_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ページ 1/100 完了 (1.0%)\n",
      "ページ 2/100 完了 (2.0%)\n",
      "ページ 3/100 完了 (3.0%)\n",
      "ページ 4/100 完了 (4.0%)\n",
      "ページ 5/100 完了 (5.0%)\n",
      "ページ 6/100 完了 (6.0%)\n",
      "ページ 7/100 完了 (7.0%)\n",
      "ページ 8/100 完了 (8.0%)\n",
      "ページ 9/100 完了 (9.0%)\n",
      "ページ 10/100 完了 (10.0%)\n",
      "ページ 11/100 完了 (11.0%)\n",
      "ページ 12/100 完了 (12.0%)\n",
      "ページ 13/100 完了 (13.0%)\n",
      "ページ 14/100 完了 (14.0%)\n",
      "ページ 15/100 完了 (15.0%)\n",
      "ページ 16/100 完了 (16.0%)\n",
      "ページ 17/100 完了 (17.0%)\n",
      "ページ 18/100 完了 (18.0%)\n",
      "ページ 19/100 完了 (19.0%)\n",
      "ページ 20/100 完了 (20.0%)\n",
      "ページ 21/100 完了 (21.0%)\n",
      "ページ 22/100 完了 (22.0%)\n",
      "ページ 23/100 完了 (23.0%)\n",
      "ページ 24/100 完了 (24.0%)\n",
      "ページ 25/100 完了 (25.0%)\n",
      "ページ 26/100 完了 (26.0%)\n",
      "ページ 27/100 完了 (27.0%)\n",
      "ページ 28/100 完了 (28.0%)\n",
      "ページ 29/100 完了 (29.0%)\n",
      "ページ 30/100 完了 (30.0%)\n",
      "ページ 31/100 完了 (31.0%)\n",
      "ページ 32/100 完了 (32.0%)\n",
      "ページ 33/100 完了 (33.0%)\n",
      "ページ 34/100 完了 (34.0%)\n",
      "ページ 35/100 完了 (35.0%)\n",
      "エラー: attempt to write a readonly database\n"
     ]
    }
   ],
   "source": [
    "### 6. メイン関数の実行\n",
    "def main():\n",
    "    conn, cursor = init_database()\n",
    "    \n",
    "    try:\n",
    "        # 最初のページで総ページ数を取得\n",
    "        first_page_soup = load_page(url.format(1))\n",
    "        max_page = get_total_pages(first_page_soup)\n",
    "        \n",
    "        for page in range(1, max_page + 1):\n",
    "            # ページ間隔を設定（サーバー負荷に配慮）\n",
    "            time.sleep(2)  # リクエスト間隔を2秒に変更\n",
    "            \n",
    "            try:\n",
    "                soup = load_page(url.format(page))\n",
    "            except Exception as e:\n",
    "                logging.error(f\"ページ {page} の取得に失敗しました: {e}\")\n",
    "                continue  # 次のページに進む\n",
    "            \n",
    "            properties = soup.find_all(class_='cassetteitem')\n",
    "            \n",
    "            all_data = []\n",
    "            for prop in properties:\n",
    "                property_data = extract_property_data(prop)\n",
    "                all_data.extend(property_data)\n",
    "            \n",
    "            # データベースに保存\n",
    "            insert_to_database(conn, cursor, all_data)\n",
    "            \n",
    "            # CSVに保存\n",
    "            save_to_csv(all_data)\n",
    "            \n",
    "            # 進捗表示\n",
    "            print(f'ページ {page}/{max_page} 完了 ({round(page/max_page*100, 2)}%)')\n",
    "            logging.info(f'ページ {page} 完了')\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"スクレイピング中にエラー発生: {e}\")\n",
    "        print(f\"エラー: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        conn.close()\n",
    "        logging.info('データベース接続終了')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
